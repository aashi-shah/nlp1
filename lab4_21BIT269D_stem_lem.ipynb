{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_2mV6Xf03q0I","outputId":"ad6f30b7-22f1-4e0f-80a8-671f0832735e","executionInfo":{"status":"ok","timestamp":1731080518169,"user_tz":-330,"elapsed":19498,"user":{"displayName":"Aashi Shah","userId":"11532052876626034690"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Stemmed Words: ['formula', '1', 'is', 'the', 'pinnacl', 'of', 'race', 'cultur', ',', 'where', 'speed', ',', 'strategi', ',', 'and', 'precis', 'come', 'togeth', 'in', 'a', 'high-stak', 'blend', 'of', 'engin', 'and', 'raw', 'skill', '.', 'with', 'car', 'that', 'push', 'the', 'limit', 'of', 'physic', 'and', 'driver', 'that', 'embodi', 'relentless', 'competit', ',', 'f1', 'captur', 'the', 'fascin', 'of', 'million', 'worldwid', '.']\n","Lemmatized Words: ['Formula', '1', 'be', 'the', 'pinnacle', 'of', 'race', 'culture', ',', 'where', 'speed', ',', 'strategy', ',', 'and', 'precision', 'come', 'together', 'in', 'a', 'high-stakes', 'blend', 'of', 'engineering', 'and', 'raw', 'skill', '.', 'With', 'car', 'that', 'push', 'the', 'limit', 'of', 'physic', 'and', 'driver', 'that', 'embody', 'relentless', 'competitiveness', ',', 'F1', 'capture', 'the', 'fascination', 'of', 'million', 'worldwide', '.']\n","\n","Comparison of Original, Stemmed, and Lemmatized Words:\n","Original: Formula \t\t\t| Stemmed: formula \t\t\t| Lemmatized: Formula\n","Original: 1 \t\t\t| Stemmed: 1 \t\t\t| Lemmatized: 1\n","Original: is \t\t\t| Stemmed: is \t\t\t| Lemmatized: be\n","Original: the \t\t\t| Stemmed: the \t\t\t| Lemmatized: the\n","Original: pinnacle \t\t\t| Stemmed: pinnacl \t\t\t| Lemmatized: pinnacle\n","Original: of \t\t\t| Stemmed: of \t\t\t| Lemmatized: of\n","Original: racing \t\t\t| Stemmed: race \t\t\t| Lemmatized: race\n","Original: culture \t\t\t| Stemmed: cultur \t\t\t| Lemmatized: culture\n","Original: , \t\t\t| Stemmed: , \t\t\t| Lemmatized: ,\n","Original: where \t\t\t| Stemmed: where \t\t\t| Lemmatized: where\n","Original: speed \t\t\t| Stemmed: speed \t\t\t| Lemmatized: speed\n","Original: , \t\t\t| Stemmed: , \t\t\t| Lemmatized: ,\n","Original: strategy \t\t\t| Stemmed: strategi \t\t\t| Lemmatized: strategy\n","Original: , \t\t\t| Stemmed: , \t\t\t| Lemmatized: ,\n","Original: and \t\t\t| Stemmed: and \t\t\t| Lemmatized: and\n","Original: precision \t\t\t| Stemmed: precis \t\t\t| Lemmatized: precision\n","Original: come \t\t\t| Stemmed: come \t\t\t| Lemmatized: come\n","Original: together \t\t\t| Stemmed: togeth \t\t\t| Lemmatized: together\n","Original: in \t\t\t| Stemmed: in \t\t\t| Lemmatized: in\n","Original: a \t\t\t| Stemmed: a \t\t\t| Lemmatized: a\n","Original: high-stakes \t\t\t| Stemmed: high-stak \t\t\t| Lemmatized: high-stakes\n","Original: blend \t\t\t| Stemmed: blend \t\t\t| Lemmatized: blend\n","Original: of \t\t\t| Stemmed: of \t\t\t| Lemmatized: of\n","Original: engineering \t\t\t| Stemmed: engin \t\t\t| Lemmatized: engineering\n","Original: and \t\t\t| Stemmed: and \t\t\t| Lemmatized: and\n","Original: raw \t\t\t| Stemmed: raw \t\t\t| Lemmatized: raw\n","Original: skill \t\t\t| Stemmed: skill \t\t\t| Lemmatized: skill\n","Original: . \t\t\t| Stemmed: . \t\t\t| Lemmatized: .\n","Original: With \t\t\t| Stemmed: with \t\t\t| Lemmatized: With\n","Original: cars \t\t\t| Stemmed: car \t\t\t| Lemmatized: car\n","Original: that \t\t\t| Stemmed: that \t\t\t| Lemmatized: that\n","Original: push \t\t\t| Stemmed: push \t\t\t| Lemmatized: push\n","Original: the \t\t\t| Stemmed: the \t\t\t| Lemmatized: the\n","Original: limits \t\t\t| Stemmed: limit \t\t\t| Lemmatized: limit\n","Original: of \t\t\t| Stemmed: of \t\t\t| Lemmatized: of\n","Original: physics \t\t\t| Stemmed: physic \t\t\t| Lemmatized: physic\n","Original: and \t\t\t| Stemmed: and \t\t\t| Lemmatized: and\n","Original: drivers \t\t\t| Stemmed: driver \t\t\t| Lemmatized: driver\n","Original: that \t\t\t| Stemmed: that \t\t\t| Lemmatized: that\n","Original: embody \t\t\t| Stemmed: embodi \t\t\t| Lemmatized: embody\n","Original: relentless \t\t\t| Stemmed: relentless \t\t\t| Lemmatized: relentless\n","Original: competitiveness \t\t\t| Stemmed: competit \t\t\t| Lemmatized: competitiveness\n","Original: , \t\t\t| Stemmed: , \t\t\t| Lemmatized: ,\n","Original: F1 \t\t\t| Stemmed: f1 \t\t\t| Lemmatized: F1\n","Original: captures \t\t\t| Stemmed: captur \t\t\t| Lemmatized: capture\n","Original: the \t\t\t| Stemmed: the \t\t\t| Lemmatized: the\n","Original: fascination \t\t\t| Stemmed: fascin \t\t\t| Lemmatized: fascination\n","Original: of \t\t\t| Stemmed: of \t\t\t| Lemmatized: of\n","Original: millions \t\t\t| Stemmed: million \t\t\t| Lemmatized: million\n","Original: worldwide \t\t\t| Stemmed: worldwid \t\t\t| Lemmatized: worldwide\n","Original: . \t\t\t| Stemmed: . \t\t\t| Lemmatized: .\n"]}],"source":["# Stemming and Lemmatization Techniques in Text Preprocessing\n","import nltk\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import wordnet\n","\n","# Download required resources\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","\n","# Initialize stemmer and lemmatizer\n","stemmer = PorterStemmer()\n","lemmatizer = WordNetLemmatizer()\n","\n","# Function to get WordNet POS tags for more accurate lemmatization\n","def get_wordnet_pos(word):\n","    tag = nltk.pos_tag([word])[0][1][0].upper()  # Get the first letter of POS tag\n","    tag_dict = {\"J\": wordnet.ADJ,\n","                \"N\": wordnet.NOUN,\n","                \"V\": wordnet.VERB,\n","                \"R\": wordnet.ADV}\n","    return tag_dict.get(tag, wordnet.NOUN)  # Default to NOUN if not found\n","\n","# Function for stemming\n","def stem_words(text):\n","    tokens = word_tokenize(text)\n","    return [stemmer.stem(word) for word in tokens]\n","\n","# Function for lemmatization (with POS tagging)\n","def lemmatize_words(text):\n","    tokens = word_tokenize(text)\n","    return [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in tokens]\n","\n","# Example text\n","text = \"\"\"Formula 1 is the pinnacle of racing culture, where speed, strategy, and precision come together in a high-stakes blend of engineering and raw skill.\n"," With cars that push the limits of physics and drivers that embody relentless competitiveness, F1 captures the fascination of millions worldwide.\"\"\"\n","\n","# Perform stemming\n","stemmed_words = stem_words(text)\n","print(\"Stemmed Words:\", stemmed_words)\n","\n","# Perform lemmatization\n","lemmatized_words = lemmatize_words(text)\n","print(\"Lemmatized Words:\", lemmatized_words)\n","\n","# BONUS: Compare stemmed and lemmatized results side by side\n","print(\"\\nComparison of Original, Stemmed, and Lemmatized Words:\")\n","tokens = word_tokenize(text)\n","for i, token in enumerate(tokens):\n","    print(f\"Original: {token} \\t\\t\\t| Stemmed: {stemmed_words[i]} \\t\\t\\t| Lemmatized: {lemmatized_words[i]}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7Sh7CLJb0N8"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.3"}},"nbformat":4,"nbformat_minor":0}